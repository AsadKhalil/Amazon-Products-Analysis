{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced Recommender Systems\n",
        "## Matrix Factorization (SVD) & Neural Collaborative Filtering (NCF)\n",
        "\n",
        "**Techniques Covered:**\n",
        "1. **SVD (Singular Value Decomposition)** - Matrix factorization using Surprise library\n",
        "2. **Neural Collaborative Filtering (NCF)** - Deep learning approach with user/item embeddings\n",
        "3. **Hyperparameter Tuning** - Grid search for latent factors, learning rate, epochs\n",
        "\n",
        "**Goal:** Compare traditional CF/Hybrid models with state-of-the-art matrix factorization and deep learning approaches.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (run once)\n",
        "# !pip install scikit-surprise torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/home/tk-lpt-0806/.pyenv/versions/3.10.12/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/home/tk-lpt-0806/.pyenv/versions/3.10.12/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/home/tk-lpt-0806/.pyenv/versions/3.10.12/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/home/tk-lpt-0806/.pyenv/versions/3.10.12/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/home/tk-lpt-0806/.pyenv/versions/3.10.12/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/ipykernel/utils.py\", line 71, in preserve_context\n",
            "    return await f(*args, **kwargs)\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
            "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
            "    await result\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipykernel_2342510/4083626119.py\", line 15, in <module>\n",
            "    from surprise import SVD, Dataset, Reader, accuracy\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/surprise/__init__.py\", line 6, in <module>\n",
            "    from .prediction_algorithms import (\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/surprise/prediction_algorithms/__init__.py\", line 23, in <module>\n",
            "    from .algo_base import AlgoBase\n",
            "  File \"/home/tk-lpt-0806/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/surprise/prediction_algorithms/algo_base.py\", line 8, in <module>\n",
            "    from .. import similarities as sims\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "numpy.core.multiarray failed to import (auto-generated because you didn't call 'numpy.import_array()' after cimporting numpy; use '<void>numpy._import_array' to disable if you are certain you don't need it).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Surprise for SVD\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SVD, Dataset, Reader, accuracy\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV, cross_validate\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# PyTorch for NCF\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/surprise/__init__.py:6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuiltin_datasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_dataset_dir\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprediction_algorithms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     AlgoBase,\n\u001b[1;32m      8\u001b[0m     BaselineOnly,\n\u001b[1;32m      9\u001b[0m     CoClustering,\n\u001b[1;32m     10\u001b[0m     KNNBaseline,\n\u001b[1;32m     11\u001b[0m     KNNBasic,\n\u001b[1;32m     12\u001b[0m     KNNWithMeans,\n\u001b[1;32m     13\u001b[0m     KNNWithZScore,\n\u001b[1;32m     14\u001b[0m     NMF,\n\u001b[1;32m     15\u001b[0m     NormalPredictor,\n\u001b[1;32m     16\u001b[0m     Prediction,\n\u001b[1;32m     17\u001b[0m     PredictionImpossible,\n\u001b[1;32m     18\u001b[0m     SlopeOne,\n\u001b[1;32m     19\u001b[0m     SVD,\n\u001b[1;32m     20\u001b[0m     SVDpp,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Reader\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Trainset\n",
            "File \u001b[0;32m~/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/surprise/prediction_algorithms/__init__.py:23\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`prediction_algorithms` package includes the prediction algorithms\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mavailable for recommendation.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    co_clustering.CoClustering\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgo_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AlgoBase\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbaseline_only\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaselineOnly\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mco_clustering\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CoClustering\n",
            "File \u001b[0;32m~/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/surprise/prediction_algorithms/algo_base.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`surprise.prediction_algorithms.algo_base` module defines the base\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mclass :class:`AlgoBase` from which every single prediction algorithm has to\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03minherit.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mheapq\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m similarities \u001b[38;5;28;01mas\u001b[39;00m sims\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize_baselines\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m baseline_als, baseline_sgd\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Prediction, PredictionImpossible\n",
            "File \u001b[0;32m~/Desktop/MSDS/SEM3/Recommender System/Project/.venv/lib/python3.10/site-packages/surprise/similarities.pyx:1\u001b[0m, in \u001b[0;36minit surprise.similarities\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import (auto-generated because you didn't call 'numpy.import_array()' after cimporting numpy; use '<void>numpy._import_array' to disable if you are certain you don't need it)."
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import hashlib\n",
        "import pickle\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Surprise for SVD\n",
        "from surprise import SVD, Dataset, Reader, accuracy\n",
        "from surprise.model_selection import GridSearchCV, cross_validate\n",
        "\n",
        "# PyTorch for NCF\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette('husl')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 11\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load enhanced data\n",
        "DATA_PATH = '../data/processed/enhanced_home_kitchen_qa.pkl'\n",
        "\n",
        "print(f\"Loading data from: {DATA_PATH}\")\n",
        "df = pd.read_pickle(DATA_PATH)\n",
        "\n",
        "print(f\"✓ Data loaded successfully!\")\n",
        "print(f\"Total records: {len(df):,}\")\n",
        "print(f\"Columns: {len(df.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare user-item-rating data\n",
        "print(\"Preparing user-item-rating dataset...\")\n",
        "\n",
        "# Aggregate by user-item pairs\n",
        "user_item_df = df.groupby(['user_id', 'asin']).agg({\n",
        "    'rating': 'mean',\n",
        "    'sentiment_compound': 'mean',\n",
        "    'answer': 'count'\n",
        "}).reset_index()\n",
        "user_item_df.columns = ['user_id', 'asin', 'rating', 'sentiment', 'interaction_count']\n",
        "\n",
        "# Filter for quality\n",
        "MIN_USER_INTERACTIONS = 2\n",
        "MIN_ITEM_INTERACTIONS = 5\n",
        "\n",
        "user_counts = user_item_df.groupby('user_id').size()\n",
        "item_counts = user_item_df.groupby('asin').size()\n",
        "\n",
        "valid_users = user_counts[user_counts >= MIN_USER_INTERACTIONS].index\n",
        "valid_items = item_counts[item_counts >= MIN_ITEM_INTERACTIONS].index\n",
        "\n",
        "data_df = user_item_df[\n",
        "    (user_item_df['user_id'].isin(valid_users)) & \n",
        "    (user_item_df['asin'].isin(valid_items))\n",
        "].copy()\n",
        "\n",
        "print(f\"✓ Dataset prepared:\")\n",
        "print(f\"  Interactions: {len(data_df):,}\")\n",
        "print(f\"  Users: {data_df['user_id'].nunique():,}\")\n",
        "print(f\"  Items: {data_df['asin'].nunique():,}\")\n",
        "print(f\"  Sparsity: {1 - len(data_df) / (data_df['user_id'].nunique() * data_df['asin'].nunique()):.4%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create mappings for users and items\n",
        "user_to_idx = {user: idx for idx, user in enumerate(data_df['user_id'].unique())}\n",
        "idx_to_user = {idx: user for user, idx in user_to_idx.items()}\n",
        "item_to_idx = {item: idx for idx, item in enumerate(data_df['asin'].unique())}\n",
        "idx_to_item = {idx: item for item, idx in item_to_idx.items()}\n",
        "\n",
        "# Add indices to dataframe\n",
        "data_df['user_idx'] = data_df['user_id'].map(user_to_idx)\n",
        "data_df['item_idx'] = data_df['asin'].map(item_to_idx)\n",
        "\n",
        "n_users = len(user_to_idx)\n",
        "n_items = len(item_to_idx)\n",
        "\n",
        "print(f\"User indices: 0-{n_users-1}\")\n",
        "print(f\"Item indices: 0-{n_items-1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train-test split\n",
        "print(\"\\nSplitting data (80/20)...\")\n",
        "train_df, test_df = train_test_split(data_df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set: {len(train_df):,} interactions\")\n",
        "print(f\"Test set: {len(test_df):,} interactions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. SVD (Matrix Factorization) - Surprise Library\n",
        "\n",
        "Singular Value Decomposition factorizes the user-item matrix into user and item latent factors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for Surprise\n",
        "print(\"Preparing data for Surprise library...\")\n",
        "\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Create Surprise datasets\n",
        "train_surprise = Dataset.load_from_df(\n",
        "    train_df[['user_id', 'asin', 'rating']], \n",
        "    reader\n",
        ").build_full_trainset()\n",
        "\n",
        "test_surprise = [(row['user_id'], row['asin'], row['rating']) \n",
        "                 for _, row in test_df.iterrows()]\n",
        "\n",
        "print(f\"✓ Surprise datasets created\")\n",
        "print(f\"  Training: {train_surprise.n_ratings} ratings\")\n",
        "print(f\"  Test: {len(test_surprise)} ratings\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train baseline SVD with default parameters\n",
        "print(\"\\nTraining baseline SVD...\")\n",
        "svd_baseline = SVD(n_factors=100, n_epochs=20, random_state=42, verbose=True)\n",
        "svd_baseline.fit(train_surprise)\n",
        "\n",
        "# Evaluate on test set\n",
        "predictions = svd_baseline.test(test_surprise)\n",
        "rmse_baseline = accuracy.rmse(predictions, verbose=False)\n",
        "mae_baseline = accuracy.mae(predictions, verbose=False)\n",
        "\n",
        "print(f\"\\nBaseline SVD Results:\")\n",
        "print(f\"  RMSE: {rmse_baseline:.4f}\")\n",
        "print(f\"  MAE: {mae_baseline:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Hyperparameter Tuning - Grid Search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_factors': [50, 100, 150],         # Latent factors\n",
        "    'n_epochs': [10, 20, 30],            # Training epochs\n",
        "    'lr_all': [0.005, 0.01],             # Learning rate\n",
        "    'reg_all': [0.02, 0.05]              # Regularization\n",
        "}\n",
        "\n",
        "print(\"Starting Grid Search for SVD...\")\n",
        "print(f\"Parameter combinations: {np.prod([len(v) for v in param_grid.values()])}\")\n",
        "print(f\"CV folds: 3\")\n",
        "print(\"\\nThis may take a few minutes...\\n\")\n",
        "\n",
        "# Grid search with cross-validation\n",
        "gs = GridSearchCV(\n",
        "    SVD, \n",
        "    param_grid, \n",
        "    measures=['rmse', 'mae'], \n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    joblib_verbose=2\n",
        ")\n",
        "\n",
        "# Create full dataset for cross-validation\n",
        "full_data = Dataset.load_from_df(\n",
        "    data_df[['user_id', 'asin', 'rating']], \n",
        "    reader\n",
        ")\n",
        "\n",
        "gs.fit(full_data)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GRID SEARCH RESULTS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nBest RMSE score: {gs.best_score['rmse']:.4f}\")\n",
        "print(f\"Best parameters:\")\n",
        "for param, value in gs.best_params['rmse'].items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train final SVD model with best parameters\n",
        "print(\"\\nTraining SVD with best parameters...\")\n",
        "best_params = gs.best_params['rmse']\n",
        "\n",
        "svd_tuned = SVD(\n",
        "    n_factors=best_params['n_factors'],\n",
        "    n_epochs=best_params['n_epochs'],\n",
        "    lr_all=best_params['lr_all'],\n",
        "    reg_all=best_params['reg_all'],\n",
        "    random_state=42,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "svd_tuned.fit(train_surprise)\n",
        "\n",
        "# Evaluate on test set\n",
        "predictions_tuned = svd_tuned.test(test_surprise)\n",
        "rmse_tuned = accuracy.rmse(predictions_tuned, verbose=False)\n",
        "mae_tuned = accuracy.mae(predictions_tuned, verbose=False)\n",
        "\n",
        "print(f\"\\n✓ Tuned SVD Results:\")\n",
        "print(f\"  RMSE: {rmse_tuned:.4f} (Baseline: {rmse_baseline:.4f})\")\n",
        "print(f\"  MAE: {mae_tuned:.4f} (Baseline: {mae_baseline:.4f})\")\n",
        "print(f\"  Improvement: {((rmse_baseline - rmse_tuned) / rmse_baseline * 100):.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Neural Collaborative Filtering (NCF)\n",
        "\n",
        "NCF uses neural networks to learn user-item interactions through embeddings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define NCF Model Architecture\n",
        "class NCFModel(nn.Module):\n",
        "    def __init__(self, n_users, n_items, embedding_dim=64, hidden_layers=[128, 64, 32]):\n",
        "        super(NCFModel, self).__init__()\n",
        "        \n",
        "        # User and item embeddings\n",
        "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
        "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
        "        \n",
        "        # MLP layers\n",
        "        layers = []\n",
        "        input_dim = embedding_dim * 2\n",
        "        \n",
        "        for hidden_dim in hidden_layers:\n",
        "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.2))\n",
        "            input_dim = hidden_dim\n",
        "        \n",
        "        # Final prediction layer\n",
        "        layers.append(nn.Linear(input_dim, 1))\n",
        "        \n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        \n",
        "        # Initialize weights\n",
        "        self._init_weights()\n",
        "    \n",
        "    def _init_weights(self):\n",
        "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
        "        nn.init.normal_(self.item_embedding.weight, std=0.01)\n",
        "        \n",
        "        for layer in self.mlp:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                nn.init.xavier_uniform_(layer.weight)\n",
        "                nn.init.zeros_(layer.bias)\n",
        "    \n",
        "    def forward(self, user_ids, item_ids):\n",
        "        user_emb = self.user_embedding(user_ids)\n",
        "        item_emb = self.item_embedding(item_ids)\n",
        "        \n",
        "        # Concatenate embeddings\n",
        "        x = torch.cat([user_emb, item_emb], dim=1)\n",
        "        \n",
        "        # Pass through MLP\n",
        "        output = self.mlp(x)\n",
        "        \n",
        "        # Scale output to rating range [1, 5]\n",
        "        output = torch.sigmoid(output) * 4 + 1\n",
        "        \n",
        "        return output.squeeze()\n",
        "\n",
        "print(\"✓ NCF Model architecture defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare PyTorch datasets\n",
        "print(\"Preparing PyTorch datasets...\")\n",
        "\n",
        "# Training data\n",
        "train_users = torch.LongTensor(train_df['user_idx'].values)\n",
        "train_items = torch.LongTensor(train_df['item_idx'].values)\n",
        "train_ratings = torch.FloatTensor(train_df['rating'].values)\n",
        "\n",
        "train_dataset = TensorDataset(train_users, train_items, train_ratings)\n",
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "\n",
        "# Test data\n",
        "test_users = torch.LongTensor(test_df['user_idx'].values)\n",
        "test_items = torch.LongTensor(test_df['item_idx'].values)\n",
        "test_ratings = torch.FloatTensor(test_df['rating'].values)\n",
        "\n",
        "test_dataset = TensorDataset(test_users, test_items, test_ratings)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "print(f\"✓ PyTorch datasets created\")\n",
        "print(f\"  Training batches: {len(train_loader)}\")\n",
        "print(f\"  Test batches: {len(test_loader)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training function\n",
        "def train_ncf(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for users, items, ratings in train_loader:\n",
        "        users = users.to(device)\n",
        "        items = items.to(device)\n",
        "        ratings = ratings.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        predictions = model(users, items)\n",
        "        loss = criterion(predictions, ratings)\n",
        "        \n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "    \n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_ncf(model, test_loader, device):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for users, items, ratings in test_loader:\n",
        "            users = users.to(device)\n",
        "            items = items.to(device)\n",
        "            \n",
        "            predictions = model(users, items)\n",
        "            \n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_targets.extend(ratings.numpy())\n",
        "    \n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_targets = np.array(all_targets)\n",
        "    \n",
        "    # Clip predictions to valid range\n",
        "    all_predictions = np.clip(all_predictions, 1, 5)\n",
        "    \n",
        "    rmse = np.sqrt(mean_squared_error(all_targets, all_predictions))\n",
        "    mae = mean_absolute_error(all_targets, all_predictions)\n",
        "    \n",
        "    return rmse, mae, all_predictions\n",
        "\n",
        "print(\"✓ Training and evaluation functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train baseline NCF model\n",
        "print(\"\\nTraining baseline NCF model...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "ncf_baseline = NCFModel(\n",
        "    n_users=n_users,\n",
        "    n_items=n_items,\n",
        "    embedding_dim=64,\n",
        "    hidden_layers=[128, 64, 32]\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(ncf_baseline.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "n_epochs = 20\n",
        "train_losses = []\n",
        "test_metrics = []\n",
        "\n",
        "print(f\"Training for {n_epochs} epochs...\")\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = train_ncf(ncf_baseline, train_loader, criterion, optimizer, device)\n",
        "    rmse, mae, _ = evaluate_ncf(ncf_baseline, test_loader, device)\n",
        "    \n",
        "    train_losses.append(train_loss)\n",
        "    test_metrics.append({'rmse': rmse, 'mae': mae})\n",
        "    \n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}: Loss={train_loss:.4f}, RMSE={rmse:.4f}, MAE={mae:.4f}\")\n",
        "\n",
        "print(\"\\n✓ Baseline NCF training complete\")\n",
        "print(f\"  Final RMSE: {test_metrics[-1]['rmse']:.4f}\")\n",
        "print(f\"  Final MAE: {test_metrics[-1]['mae']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 NCF Hyperparameter Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameter configurations to test\n",
        "ncf_configs = [\n",
        "    {'embedding_dim': 32, 'hidden_layers': [64, 32], 'lr': 0.001, 'epochs': 20},\n",
        "    {'embedding_dim': 64, 'hidden_layers': [128, 64, 32], 'lr': 0.001, 'epochs': 20},\n",
        "    {'embedding_dim': 64, 'hidden_layers': [128, 64, 32], 'lr': 0.005, 'epochs': 20},\n",
        "    {'embedding_dim': 128, 'hidden_layers': [256, 128, 64], 'lr': 0.001, 'epochs': 20},\n",
        "    {'embedding_dim': 64, 'hidden_layers': [128, 64, 32], 'lr': 0.001, 'epochs': 30},\n",
        "]\n",
        "\n",
        "print(\"Testing NCF configurations...\")\n",
        "print(f\"Total configurations: {len(ncf_configs)}\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "ncf_results = []\n",
        "\n",
        "for idx, config in enumerate(ncf_configs, 1):\n",
        "    print(f\"\\nConfiguration {idx}/{len(ncf_configs)}\")\n",
        "    print(f\"  Embedding dim: {config['embedding_dim']}\")\n",
        "    print(f\"  Hidden layers: {config['hidden_layers']}\")\n",
        "    print(f\"  Learning rate: {config['lr']}\")\n",
        "    print(f\"  Epochs: {config['epochs']}\")\n",
        "    \n",
        "    # Create model\n",
        "    model = NCFModel(\n",
        "        n_users=n_users,\n",
        "        n_items=n_items,\n",
        "        embedding_dim=config['embedding_dim'],\n",
        "        hidden_layers=config['hidden_layers']\n",
        "    ).to(device)\n",
        "    \n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
        "    \n",
        "    # Train\n",
        "    best_rmse = float('inf')\n",
        "    for epoch in range(config['epochs']):\n",
        "        train_loss = train_ncf(model, train_loader, criterion, optimizer, device)\n",
        "        rmse, mae, _ = evaluate_ncf(model, test_loader, device)\n",
        "        \n",
        "        if rmse < best_rmse:\n",
        "            best_rmse = rmse\n",
        "            best_mae = mae- Apply SVD (Surprise).\n",
        "- Implement Neural Collaborative Filtering (NCF).\n",
        "- Tune hyperparameters (latent factors, epochs).\n",
        "    \n",
        "    print(f\"  → Best RMSE: {best_rmse:.4f}, MAE: {best_mae:.4f}\")\n",
        "    \n",
        "    ncf_results.append({\n",
        "        'config': config,\n",
        "        'rmse': best_rmse,\n",
        "        'mae': best_mae\n",
        "    })\n",
        "\n",
        "# Find best configuration\n",
        "best_ncf = min(ncf_results, key=lambda x: x['rmse'])\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BEST NCF CONFIGURATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Embedding dim: {best_ncf['config']['embedding_dim']}\")\n",
        "print(f\"Hidden layers: {best_ncf['config']['hidden_layers']}\")\n",
        "print(f\"Learning rate: {best_ncf['config']['lr']}\")\n",
        "print(f\"Epochs: {best_ncf['config']['epochs']}\")\n",
        "print(f\"\\nBest RMSE: {best_ncf['rmse']:.4f}\")\n",
        "print(f\"Best MAE: {best_ncf['mae']:.4f}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train final NCF model with best configuration\n",
        "print(\"\\nTraining final NCF model with best configuration...\")\n",
        "\n",
        "best_config = best_ncf['config']\n",
        "\n",
        "ncf_final = NCFModel(\n",
        "    n_users=n_users,\n",
        "    n_items=n_items,\n",
        "    embedding_dim=best_config['embedding_dim'],\n",
        "    hidden_layers=best_config['hidden_layers']\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(ncf_final.parameters(), lr=best_config['lr'])\n",
        "\n",
        "# Training with detailed tracking\n",
        "final_train_losses = []\n",
        "final_test_rmse = []\n",
        "final_test_mae = []\n",
        "\n",
        "print(f\"Training for {best_config['epochs']} epochs...\")\n",
        "for epoch in range(best_config['epochs']):\n",
        "    train_loss = train_ncf(ncf_final, train_loader, criterion, optimizer, device)\n",
        "    rmse, mae, _ = evaluate_ncf(ncf_final, test_loader, device)\n",
        "    \n",
        "    final_train_losses.append(train_loss)\n",
        "    final_test_rmse.append(rmse)\n",
        "    final_test_mae.append(mae)\n",
        "    \n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{best_config['epochs']}: Loss={train_loss:.4f}, RMSE={rmse:.4f}, MAE={mae:.4f}\")\n",
        "\n",
        "# Final evaluation\n",
        "final_rmse, final_mae, ncf_predictions = evaluate_ncf(ncf_final, test_loader, device)\n",
        "\n",
        "print(\"\\n✓ Final NCF model trained!\")\n",
        "print(f\"  Final RMSE: {final_rmse:.4f}\")\n",
        "print(f\"  Final MAE: {final_mae:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Comprehensive Model Comparison\n",
        "\n",
        "Compare all models: Traditional CF, Hybrid, SVD, and NCF.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load previous model results for comparison\n",
        "print(\"Loading previous model results...\")\n",
        "\n",
        "# Try to load hybrid model results\n",
        "try:\n",
        "    hybrid_results = pd.read_csv('../data/results/hybrid_model_comparison.csv')\n",
        "    print(f\"✓ Loaded {len(hybrid_results)} hybrid model results\")\n",
        "except FileNotFoundError:\n",
        "    print(\"⚠ Hybrid model results not found, will compare only advanced models\")\n",
        "    hybrid_results = None\n",
        "\n",
        "# Try to load CF results\n",
        "try:\n",
        "    cf_results = pd.read_csv('../data/results/cf_evaluation_results.csv')\n",
        "    print(f\"✓ Loaded {len(cf_results)} CF model results\")\n",
        "except FileNotFoundError:\n",
        "    print(\"⚠ CF results not found\")\n",
        "    cf_results = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive comparison\n",
        "print(\"\\nCreating comprehensive comparison...\")\n",
        "\n",
        "all_results = []\n",
        "\n",
        "# Add baseline (global mean)\n",
        "test_ratings = test_df['rating'].values\n",
        "global_mean = train_df['rating'].mean()\n",
        "baseline_pred = np.full(len(test_ratings), global_mean)\n",
        "baseline_rmse = np.sqrt(mean_squared_error(test_ratings, baseline_pred))\n",
        "baseline_mae = mean_absolute_error(test_ratings, baseline_pred)\n",
        "\n",
        "all_results.append({\n",
        "    'Model': 'Baseline (Global Mean)',\n",
        "    'Category': 'Baseline',\n",
        "    'RMSE': baseline_rmse,\n",
        "    'MAE': baseline_mae\n",
        "})\n",
        "\n",
        "# Add SVD results\n",
        "all_results.append({\n",
        "    'Model': 'SVD (Baseline)',\n",
        "    'Category': 'Matrix Factorization',\n",
        "    'RMSE': rmse_baseline,\n",
        "    'MAE': mae_baseline\n",
        "})\n",
        "\n",
        "all_results.append({\n",
        "    'Model': 'SVD (Tuned)',\n",
        "    'Category': 'Matrix Factorization',\n",
        "    'RMSE': rmse_tuned,\n",
        "    'MAE': mae_tuned\n",
        "})\n",
        "\n",
        "# Add NCF results\n",
        "all_results.append({\n",
        "    'Model': 'NCF (Baseline)',\n",
        "    'Category': 'Deep Learning',\n",
        "    'RMSE': test_metrics[-1]['rmse'],\n",
        "    'MAE': test_metrics[-1]['mae']\n",
        "})\n",
        "\n",
        "all_results.append({\n",
        "    'Model': 'NCF (Tuned)',\n",
        "    'Category': 'Deep Learning',\n",
        "    'RMSE': final_rmse,\n",
        "    'MAE': final_mae\n",
        "})\n",
        "\n",
        "# Add previous results if available\n",
        "if hybrid_results is not None:\n",
        "    for _, row in hybrid_results.iterrows():\n",
        "        category = 'Traditional CF' if 'CF:' in row['Model'] or 'Pure CF' in row['Model'] else 'Hybrid'\n",
        "        all_results.append({\n",
        "            'Model': row['Model'],\n",
        "            'Category': category,\n",
        "            'RMSE': row['RMSE'],\n",
        "            'MAE': row['MAE']\n",
        "        })\n",
        "\n",
        "# Create dataframe and sort\n",
        "comparison_df = pd.DataFrame(all_results)\n",
        "comparison_df = comparison_df.sort_values('RMSE')\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPREHENSIVE MODEL COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save comprehensive results\n",
        "OUTPUT_DIR = '../data/results/'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "comparison_path = os.path.join(OUTPUT_DIR, 'comprehensive_model_comparison.csv')\n",
        "comparison_df.to_csv(comparison_path, index=False)\n",
        "print(f\"\\n✓ Comprehensive results saved to: {comparison_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 1: Comprehensive Model Comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Advanced Recommender Systems: Comprehensive Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Color mapping by category\n",
        "category_colors = {\n",
        "    'Baseline': '#95a5a6',\n",
        "    'Traditional CF': '#e74c3c',\n",
        "    'Hybrid': '#3498db',\n",
        "    'Matrix Factorization': '#9b59b6',\n",
        "    'Deep Learning': '#2ecc71'\n",
        "}\n",
        "\n",
        "model_colors = [category_colors.get(cat, '#34495e') for cat in comparison_df['Category']]\n",
        "\n",
        "# 1. RMSE Comparison\n",
        "ax1 = axes[0, 0]\n",
        "y_pos = np.arange(len(comparison_df))\n",
        "ax1.barh(y_pos, comparison_df['RMSE'], color=model_colors, edgecolor='black', linewidth=1.2)\n",
        "ax1.set_yticks(y_pos)\n",
        "ax1.set_yticklabels(comparison_df['Model'], fontsize=9)\n",
        "ax1.set_xlabel('RMSE (Lower is Better)', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Root Mean Square Error', fontsize=13, fontweight='bold')\n",
        "ax1.invert_yaxis()\n",
        "ax1.grid(axis='x', alpha=0.3)\n",
        "for i, v in enumerate(comparison_df['RMSE']):\n",
        "    ax1.text(v + 0.01, i, f'{v:.4f}', va='center', fontsize=8, fontweight='bold')\n",
        "\n",
        "# 2. MAE Comparison\n",
        "ax2 = axes[0, 1]\n",
        "ax2.barh(y_pos, comparison_df['MAE'], color=model_colors, edgecolor='black', linewidth=1.2)\n",
        "ax2.set_yticks(y_pos)\n",
        "ax2.set_yticklabels(comparison_df['Model'], fontsize=9)\n",
        "ax2.set_xlabel('MAE (Lower is Better)', fontsize=12, fontweight='bold')\n",
        "ax2.set_title('Mean Absolute Error', fontsize=13, fontweight='bold')\n",
        "ax2.invert_yaxis()\n",
        "ax2.grid(axis='x', alpha=0.3)\n",
        "for i, v in enumerate(comparison_df['MAE']):\n",
        "    ax2.text(v + 0.01, i, f'{v:.4f}', va='center', fontsize=8, fontweight='bold')\n",
        "\n",
        "# 3. Category-wise Performance\n",
        "ax3 = axes[1, 0]\n",
        "category_stats = comparison_df.groupby('Category').agg({'RMSE': 'mean', 'MAE': 'mean'}).reset_index()\n",
        "category_stats = category_stats.sort_values('RMSE')\n",
        "cat_colors = [category_colors[cat] for cat in category_stats['Category']]\n",
        "x_pos = np.arange(len(category_stats))\n",
        "width = 0.35\n",
        "ax3.bar(x_pos - width/2, category_stats['RMSE'], width, label='RMSE', color=cat_colors, \n",
        "        edgecolor='black', alpha=0.7)\n",
        "ax3.bar(x_pos + width/2, category_stats['MAE'], width, label='MAE', color=cat_colors, \n",
        "        edgecolor='black', alpha=0.4)\n",
        "ax3.set_xticks(x_pos)\n",
        "ax3.set_xticklabels(category_stats['Category'], rotation=45, ha='right', fontsize=10)\n",
        "ax3.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
        "ax3.set_title('Average Performance by Category', fontsize=13, fontweight='bold')\n",
        "ax3.legend(fontsize=10)\n",
        "ax3.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 4. Top Models Comparison\n",
        "ax4 = axes[1, 1]\n",
        "top_models = comparison_df.head(5)\n",
        "models_abbrev = [m[:25] for m in top_models['Model']]\n",
        "x_pos = np.arange(len(top_models))\n",
        "top_colors = [category_colors[cat] for cat in top_models['Category']]\n",
        "ax4.bar(x_pos, top_models['RMSE'], color=top_colors, edgecolor='black', linewidth=1.2)\n",
        "ax4.set_xticks(x_pos)\n",
        "ax4.set_xticklabels(models_abbrev, rotation=45, ha='right', fontsize=9)\n",
        "ax4.set_ylabel('RMSE', fontsize=12, fontweight='bold')\n",
        "ax4.set_title('Top 5 Models by RMSE', fontsize=13, fontweight='bold')\n",
        "ax4.grid(axis='y', alpha=0.3)\n",
        "for i, v in enumerate(top_models['RMSE']):\n",
        "    ax4.text(i, v + 0.01, f'{v:.4f}', ha='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save plot\n",
        "VIZ_DIR = '../visualizations/advanced/'\n",
        "os.makedirs(VIZ_DIR, exist_ok=True)\n",
        "plot_path = os.path.join(VIZ_DIR, 'comprehensive_comparison.png')\n",
        "plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"\\n✓ Comprehensive comparison plot saved to: {plot_path}\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 2: NCF Training Progress\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "fig.suptitle('NCF Training Progress', fontsize=16, fontweight='bold')\n",
        "\n",
        "epochs = np.arange(1, len(final_train_losses) + 1)\n",
        "\n",
        "# Training loss\n",
        "ax1 = axes[0]\n",
        "ax1.plot(epochs, final_train_losses, marker='o', linewidth=2, markersize=5, color='#3498db')\n",
        "ax1.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Training Loss (MSE)', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Training Loss', fontsize=13, fontweight='bold')\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# Test RMSE\n",
        "ax2 = axes[1]\n",
        "ax2.plot(epochs, final_test_rmse, marker='s', linewidth=2, markersize=5, color='#e74c3c')\n",
        "ax2.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel('Test RMSE', fontsize=12, fontweight='bold')\n",
        "ax2.set_title('Test RMSE', fontsize=13, fontweight='bold')\n",
        "ax2.grid(alpha=0.3)\n",
        "# Mark best RMSE\n",
        "best_epoch = np.argmin(final_test_rmse) + 1\n",
        "ax2.axvline(best_epoch, color='green', linestyle='--', linewidth=2, label=f'Best: Epoch {best_epoch}')\n",
        "ax2.legend()\n",
        "\n",
        "# Test MAE\n",
        "ax3 = axes[2]\n",
        "ax3.plot(epochs, final_test_mae, marker='^', linewidth=2, markersize=5, color='#9b59b6')\n",
        "ax3.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "ax3.set_ylabel('Test MAE', fontsize=12, fontweight='bold')\n",
        "ax3.set_title('Test MAE', fontsize=13, fontweight='bold')\n",
        "ax3.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "training_plot_path = os.path.join(VIZ_DIR, 'ncf_training_progress.png')\n",
        "plt.savefig(training_plot_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"✓ NCF training progress plot saved to: {training_plot_path}\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 3: SVD vs NCF Predictions\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "fig.suptitle('Prediction Comparison: SVD vs NCF', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Extract predictions\n",
        "svd_pred = [pred.est for pred in predictions_tuned]\n",
        "test_actual = test_df['rating'].values\n",
        "\n",
        "# SVD scatter\n",
        "ax1 = axes[0]\n",
        "ax1.scatter(test_actual, svd_pred, alpha=0.3, s=10, color='#9b59b6', edgecolors='none')\n",
        "ax1.plot([1, 5], [1, 5], 'r--', lw=2, label='Perfect Prediction')\n",
        "ax1.set_xlabel('Actual Rating', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Predicted Rating', fontsize=12, fontweight='bold')\n",
        "ax1.set_title(f'SVD (Tuned)\\nRMSE: {rmse_tuned:.4f} | MAE: {mae_tuned:.4f}', \n",
        "              fontsize=13, fontweight='bold')\n",
        "ax1.set_xlim(0.5, 5.5)\n",
        "ax1.set_ylim(0.5, 5.5)\n",
        "ax1.legend(loc='upper left', fontsize=10)\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# NCF scatter\n",
        "ax2 = axes[1]\n",
        "ax2.scatter(test_actual, ncf_predictions, alpha=0.3, s=10, color='#2ecc71', edgecolors='none')\n",
        "ax2.plot([1, 5], [1, 5], 'r--', lw=2, label='Perfect Prediction')\n",
        "ax2.set_xlabel('Actual Rating', fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel('Predicted Rating', fontsize=12, fontweight='bold')\n",
        "ax2.set_title(f'NCF (Tuned)\\nRMSE: {final_rmse:.4f} | MAE: {final_mae:.4f}', \n",
        "              fontsize=13, fontweight='bold')\n",
        "ax2.set_xlim(0.5, 5.5)\n",
        "ax2.set_ylim(0.5, 5.5)\n",
        "ax2.legend(loc='upper left', fontsize=10)\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "predictions_plot_path = os.path.join(VIZ_DIR, 'svd_vs_ncf_predictions.png')\n",
        "plt.savefig(predictions_plot_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"✓ SVD vs NCF predictions plot saved to: {predictions_plot_path}\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Save Trained Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save trained models\n",
        "MODEL_DIR = '../models/'\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Save SVD model\n",
        "svd_model_path = os.path.join(MODEL_DIR, 'svd_tuned.pkl')\n",
        "with open(svd_model_path, 'wb') as f:\n",
        "    pickle.dump(svd_tuned, f)\n",
        "print(f\"✓ SVD model saved to: {svd_model_path}\")\n",
        "\n",
        "# Save NCF model\n",
        "ncf_model_path = os.path.join(MODEL_DIR, 'ncf_tuned.pth')\n",
        "torch.save({\n",
        "    'model_state_dict': ncf_final.state_dict(),\n",
        "    'config': best_config,\n",
        "    'n_users': n_users,\n",
        "    'n_items': n_items,\n",
        "    'user_to_idx': user_to_idx,\n",
        "    'item_to_idx': item_to_idx\n",
        "}, ncf_model_path)\n",
        "print(f\"✓ NCF model saved to: {ncf_model_path}\")\n",
        "\n",
        "# Save mappings\n",
        "mappings_path = os.path.join(MODEL_DIR, 'user_item_mappings.pkl')\n",
        "with open(mappings_path, 'wb') as f:\n",
        "    pickle.dump({\n",
        "        'user_to_idx': user_to_idx,\n",
        "        'idx_to_user': idx_to_user,\n",
        "        'item_to_idx': item_to_idx,\n",
        "        'idx_to_item': idx_to_item,\n",
        "        'n_users': n_users,\n",
        "        'n_items': n_items\n",
        "    }, f)\n",
        "print(f\"✓ User-item mappings saved to: {mappings_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. Key Findings and Insights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comprehensive insights\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"KEY FINDINGS: ADVANCED RECOMMENDER SYSTEMS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "best_model = comparison_df.iloc[0]\n",
        "print(f\"\\n1. BEST OVERALL MODEL:\")\n",
        "print(f\"   Model: {best_model['Model']}\")\n",
        "print(f\"   Category: {best_model['Category']}\")\n",
        "print(f\"   RMSE: {best_model['RMSE']:.4f}\")\n",
        "print(f\"   MAE: {best_model['MAE']:.4f}\")\n",
        "\n",
        "print(f\"\\n2. SVD PERFORMANCE:\")\n",
        "print(f\"   Baseline SVD:  RMSE={rmse_baseline:.4f}, MAE={mae_baseline:.4f}\")\n",
        "print(f\"   Tuned SVD:     RMSE={rmse_tuned:.4f}, MAE={mae_tuned:.4f}\")\n",
        "svd_improvement = ((rmse_baseline - rmse_tuned) / rmse_baseline) * 100\n",
        "print(f\"   Improvement from tuning: {svd_improvement:.2f}%\")\n",
        "print(f\"   Best parameters: n_factors={best_params['n_factors']}, n_epochs={best_params['n_epochs']}\")\n",
        "\n",
        "print(f\"\\n3. NCF PERFORMANCE:\")\n",
        "print(f\"   Baseline NCF:  RMSE={test_metrics[-1]['rmse']:.4f}, MAE={test_metrics[-1]['mae']:.4f}\")\n",
        "print(f\"   Tuned NCF:     RMSE={final_rmse:.4f}, MAE={final_mae:.4f}\")\n",
        "ncf_improvement = ((test_metrics[-1]['rmse'] - final_rmse) / test_metrics[-1]['rmse']) * 100\n",
        "print(f\"   Improvement from tuning: {ncf_improvement:.2f}%\")\n",
        "print(f\"   Best config: embedding_dim={best_config['embedding_dim']}, lr={best_config['lr']}\")\n",
        "\n",
        "print(f\"\\n4. SVD vs NCF:\")\n",
        "if rmse_tuned < final_rmse:\n",
        "    diff = ((final_rmse - rmse_tuned) / rmse_tuned) * 100\n",
        "    print(f\"   SVD outperforms NCF by {diff:.2f}%\")\n",
        "else:\n",
        "    diff = ((rmse_tuned - final_rmse) / final_rmse) * 100\n",
        "    print(f\"   NCF outperforms SVD by {diff:.2f}%\")\n",
        "\n",
        "print(f\"\\n5. IMPROVEMENT OVER BASELINE:\")\n",
        "baseline_rmse_comp = baseline_rmse\n",
        "improvement = ((baseline_rmse_comp - best_model['RMSE']) / baseline_rmse_comp) * 100\n",
        "print(f\"   Best model improves {improvement:.2f}% over global mean baseline\")\n",
        "\n",
        "print(f\"\\n6. CATEGORY PERFORMANCE RANKING:\")\n",
        "cat_ranking = comparison_df.groupby('Category')['RMSE'].mean().sort_values()\n",
        "for rank, (category, rmse) in enumerate(cat_ranking.items(), 1):\n",
        "    print(f\"   {rank}. {category}: {rmse:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CONCLUSIONS\")\n",
        "print(\"=\"*80)\n",
        "print(\"\"\"\n",
        "The advanced recommender system analysis reveals:\n",
        "\n",
        "1. MATRIX FACTORIZATION (SVD):\n",
        "   - Highly effective for collaborative filtering\n",
        "   - Hyperparameter tuning provides measurable improvements\n",
        "   - Computationally efficient and scalable\n",
        "   - Strong baseline for rating prediction\n",
        "\n",
        "2. NEURAL COLLABORATIVE FILTERING (NCF):\n",
        "   - Deep learning approach with user/item embeddings\n",
        "   - Can capture complex non-linear patterns\n",
        "   - Requires careful hyperparameter tuning (embedding dim, architecture, lr)\n",
        "   - More computationally expensive but flexible\n",
        "\n",
        "3. COMPARATIVE INSIGHTS:\n",
        "   - Both SVD and NCF significantly outperform naive baselines\n",
        "   - Matrix factorization provides excellent performance with lower complexity\n",
        "   - Deep learning shows promise with proper architecture and training\n",
        "   - Hybrid approaches combining CF and content features remain competitive\n",
        "\n",
        "4. RECOMMENDATIONS FOR DEPLOYMENT:\n",
        "   - Use SVD for production systems requiring efficiency and reliability\n",
        "   - Consider NCF for scenarios with sufficient data and computational resources\n",
        "   - Combine multiple models in an ensemble for best performance\n",
        "   - Continue tuning based on specific use case requirements\n",
        "\"\"\")\n",
        "print(\"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
